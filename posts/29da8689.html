<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="https://img-blog.csdnimg.cn/20210509115542298.png">
  <link rel="icon" type="image/png" sizes="32x32" href="https://img-blog.csdnimg.cn/20210509115542298.png">
  <link rel="icon" type="image/png" sizes="16x16" href="https://img-blog.csdnimg.cn/20210509115542298.png">
  <link rel="mask-icon" href="/images/daxiongmao.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.loli.net/css?family=Noto+Serif+SC:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.3/css/all.min.css" integrity="sha256-2H3fkXt6FEmrReK448mDVGKb3WW2ZZw35gI7vqHOE4Y=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{&quot;hostname&quot;:&quot;ohxiaoyao.life&quot;,&quot;root&quot;:&quot;&#x2F;&quot;,&quot;images&quot;:&quot;&#x2F;images&quot;,&quot;scheme&quot;:&quot;Mist&quot;,&quot;version&quot;:&quot;8.4.0&quot;,&quot;exturl&quot;:false,&quot;sidebar&quot;:{&quot;position&quot;:&quot;left&quot;,&quot;display&quot;:&quot;always&quot;,&quot;padding&quot;:18,&quot;offset&quot;:12},&quot;copycode&quot;:false,&quot;bookmark&quot;:{&quot;enable&quot;:false,&quot;color&quot;:&quot;#222&quot;,&quot;save&quot;:&quot;auto&quot;},&quot;fancybox&quot;:false,&quot;mediumzoom&quot;:false,&quot;lazyload&quot;:false,&quot;pangu&quot;:false,&quot;comments&quot;:{&quot;style&quot;:&quot;tabs&quot;,&quot;active&quot;:null,&quot;storage&quot;:true,&quot;lazyload&quot;:false,&quot;nav&quot;:null},&quot;motion&quot;:{&quot;enable&quot;:&quot;motion&quot;,&quot;async&quot;:false,&quot;transition&quot;:{&quot;post_block&quot;:&quot;fadeIn&quot;,&quot;post_header&quot;:&quot;fadeInDown&quot;,&quot;post_body&quot;:&quot;fadeInDown&quot;,&quot;coll_header&quot;:&quot;fadeInLeft&quot;,&quot;sidebar&quot;:&quot;fadeInUp&quot;}},&quot;prism&quot;:false,&quot;i18n&quot;:{&quot;placeholder&quot;:&quot;搜索...&quot;,&quot;empty&quot;:&quot;没有找到任何搜索结果：${query}&quot;,&quot;hits_time&quot;:&quot;找到 ${hits} 个搜索结果（用时 ${time} 毫秒）&quot;,&quot;hits&quot;:&quot;找到 ${hits} 个搜索结果&quot;}}</script>
<meta name="description" content="关键字：Torch、神经网络摘要： 关于本周工具&#x2F;环境配置、基础理论学习、神经网络训练的初步入门总结">
<meta property="og:type" content="article">
<meta property="og:title" content="「机器学习」 V2神经网络学习和Pytorch框架入手">
<meta property="og:url" content="http://ohxiaoyao.life/posts/29da8689.html">
<meta property="og:site_name" content="ohxiaoyao.life">
<meta property="og:description" content="关键字：Torch、神经网络摘要： 关于本周工具&#x2F;环境配置、基础理论学习、神经网络训练的初步入门总结">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.loli.net/2021/07/31/v2REbKozLAZJM9B.jpg">
<meta property="og:image" content="https://i.loli.net/2021/07/31/GoVFL3nPJ67QtKY.png">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=%5Comega">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=f(x)">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=%5Calpha">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=t">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=g_t=%5Cnabla+f(w_t)">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=m_t+=+%5Cphi(g_1,+g_2,+%5Ccdots,+g_t);+V_t+=+%5Csum_%7Bi=0%7D%5E%7Bt%7D%7Bx_%7Bi%7D%5E%7B2%7D%7D">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=%5Ceta_t+=+%5Calpha+%5Ccdot+m_t+/+%5Csqrt%7BV_t%7D">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=w_%7Bt+1%7D+=+w_t+-+%5Ceta_t">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=%5Calpha">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=g_%7Bt%7D">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=w_%7Bt+1%7D+=w_t+-+%5Calpha+%5Ccdot+g_t+">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=%5Calpha">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=g_%7Bt%7D">
<meta property="article:published_time" content="2021-07-31T13:35:00.000Z">
<meta property="article:modified_time" content="2021-07-31T13:52:58.909Z">
<meta property="article:author" content="Xiao Yao">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2021/07/31/v2REbKozLAZJM9B.jpg">


<link rel="canonical" href="http://ohxiaoyao.life/posts/29da8689.html">



<script class="next-config" data-name="page" type="application/json">{&quot;sidebar&quot;:&quot;&quot;,&quot;isHome&quot;:false,&quot;isPost&quot;:true,&quot;lang&quot;:&quot;zh-CN&quot;,&quot;comments&quot;:true,&quot;permalink&quot;:&quot;http:&#x2F;&#x2F;ohxiaoyao.life&#x2F;posts&#x2F;29da8689.html&quot;,&quot;path&quot;:&quot;posts&#x2F;29da8689.html&quot;,&quot;title&quot;:&quot;「机器学习」 V2神经网络学习和Pytorch框架入手&quot;}</script>

<script class="next-config" data-name="calendar" type="application/json">&quot;&quot;</script>
<title>「机器学习」 V2神经网络学习和Pytorch框架入手 | ohxiaoyao.life</title><script src="/js/config.js"></script>
  




  
  <a href="https://github.com/OhhhPanda" class="github-corner" target="_blank" title="Follow me on GitHub" aria-label="Follow me on GitHub">
        <svg width="80" height="80" viewBox="0 0 250 250" style="fill:#222; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true">
          <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
      <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path>
        </svg>
  </a>
  
  
  
  
  
  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>
<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">

  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">ohxiaoyao.life</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li>
        <li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="nav-number">1.</span> <span class="nav-text">一  基本概念</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%8C-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83%EF%BC%9A%E5%89%8D%E5%90%91%E5%92%8C%E5%90%8E%E5%90%91%E4%BC%A0%E6%92%AD"><span class="nav-number">2.</span> <span class="nav-text">二 神经网络训练：前向和后向传播</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%89-%E5%BC%A0%E9%87%8F%EF%BC%88Tensors%EF%BC%89"><span class="nav-number">3.</span> <span class="nav-text">三  张量（Tensors）</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-%E5%BC%A0%E9%87%8F%E7%9A%84%E5%88%9B%E5%BB%BA%EF%BC%88%E4%B8%A4%E4%B8%AA%E5%B8%B8%E8%A7%81%EF%BC%89"><span class="nav-number">3.0.1.</span> <span class="nav-text">1 张量的创建（两个常见）</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-%E5%BC%A0%E9%87%8F%E7%9A%84%E8%AE%A1%E7%AE%97%E6%93%8D%E4%BD%9C"><span class="nav-number">3.0.2.</span> <span class="nav-text">2 张量的计算操作</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%9B-%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC%EF%BC%88Autograd%EF%BC%89"><span class="nav-number">4.</span> <span class="nav-text">四  自动求导（Autograd）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%94-%E4%BC%98%E5%8C%96%E5%99%A8%EF%BC%88Optimizer"><span class="nav-number">5.</span> <span class="nav-text">五 优化器（Optimizer)</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="nav-number">5.0.1.</span> <span class="nav-text">1 是什么？</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-%E6%9C%89%E5%93%AA%E4%BA%9B%EF%BC%9F"><span class="nav-number">5.0.2.</span> <span class="nav-text">2 有哪些？</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-%E6%80%8E%E4%B9%88%E9%80%89%EF%BC%9F"><span class="nav-number">5.0.3.</span> <span class="nav-text">3 怎么选？</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%AD-%E7%BB%93%E8%AF%AD"><span class="nav-number">6.</span> <span class="nav-text">六 结语</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%83-%E6%96%87%E7%8C%AE%E5%8F%8A%E8%B5%84%E6%96%99%E6%95%B4%E7%90%86"><span class="nav-number">7.</span> <span class="nav-text">七 文献及资料整理</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Xiao Yao"
      src="https://img-blog.csdnimg.cn/20210509115542298.png">
  <p class="site-author-name" itemprop="name">Xiao Yao</p>
  <div class="site-description" itemprop="description">记录生活</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">10</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/OhhhPanda" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;OhhhPanda" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:969527367@qq.com" title="E-Mail → mailto:969527367@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>

    
    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://ohxiaoyao.life/posts/29da8689.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://img-blog.csdnimg.cn/20210509115542298.png">
      <meta itemprop="name" content="Xiao Yao">
      <meta itemprop="description" content="记录生活">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ohxiaoyao.life">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          「机器学习」 V2神经网络学习和Pytorch框架入手
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-07-31 21:35:00 / 修改时间：21:52:58" itemprop="dateCreated datePublished" datetime="2021-07-31T21:35:00+08:00">2021-07-31</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>关键字：Torch、神经网络<br>摘要： 关于本周工具/环境配置、基础理论学习、神经网络训练的初步入门总结</p>
<span id="more"></span>

<h3 id="一-基本概念"><a href="#一-基本概念" class="headerlink" title="一  基本概念"></a>一  基本概念</h3><p>输入（特征Futures） –&gt;  加工成代表特征*N   –&gt;   输出</p>
<img src="https://i.loli.net/2021/07/31/v2REbKozLAZJM9B.jpg" alt="image-20210731171428542" style="zoom:45%;" />



<h3 id="二-神经网络训练：前向和后向传播"><a href="#二-神经网络训练：前向和后向传播" class="headerlink" title="二 神经网络训练：前向和后向传播"></a>二 神经网络训练：前向和后向传播</h3><ul>
<li><strong>前向传播（Forward Propagation）</strong>前向传播就是从input，经过一层层的layer，不断计算每一层的z和a，最后得到输出y^ 的过程，计算出了y^，就可以根据它和真实值y的差别来计算损失（loss）。</li>
<li><strong>反向传播（Backward Propagation）</strong>反向传播就是根据损失函数L(y^,y)来反方向地计算每一层的z、a、w、b的偏导数（梯度），从而更新参数。</li>
</ul>
<img src="https://i.loli.net/2021/07/31/GoVFL3nPJ67QtKY.png" alt="image-20210731171428542" style="zoom:67%;" />

<p>   每经过一次前向传播和反向传播之后，参数就更新一次，然后用新的参数再次循环上面的过程。这就是神经网络训练的整个过程。</p>
<h3 id="三-张量（Tensors）"><a href="#三-张量（Tensors）" class="headerlink" title="三  张量（Tensors）"></a>三  张量（Tensors）</h3><p>Tensors张量是一种特殊的数据结构，它和数组还有矩阵十分相似。（常量是0阶张量、向量是1阶张量…）</p>
<h5 id="1-张量的创建（两个常见）"><a href="#1-张量的创建（两个常见）" class="headerlink" title="1 张量的创建（两个常见）"></a>1 张量的创建（两个常见）</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">data = [[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]]  <span class="comment"># 从数据中创建tensor张量</span></span><br><span class="line">x_data = torch.tensor(data)</span><br><span class="line"><span class="built_in">print</span>(x_data)</span><br><span class="line"></span><br><span class="line">np_array = np.array(data)  <span class="comment"># 从numpy的array中创建</span></span><br><span class="line">x_np = torch.from_numpy(np_array)</span><br><span class="line"><span class="built_in">print</span>(x_np)</span><br></pre></td></tr></table></figure>



<h5 id="2-张量的计算操作"><a href="#2-张量的计算操作" class="headerlink" title="2 张量的计算操作"></a>2 张量的计算操作</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line">np_data = np.arange(<span class="number">6</span>).reshape(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"><span class="comment"># 转换成torch 的tense向量</span></span><br><span class="line">torch_data = torch.from_numpy(np_data)</span><br><span class="line"><span class="built_in">print</span>(</span><br><span class="line">    <span class="string">&#x27;\nnumpy&#x27;</span>, np_data,</span><br><span class="line">    <span class="string">&#x27;\ntorch&#x27;</span>, torch_data</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># tips：torch是通过tensor张量来进行计算的</span></span><br><span class="line"><span class="comment"># 二维数组转换为矩阵</span></span><br><span class="line">data = [[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]]</span><br><span class="line">tensor = torch.FloatTensor(data)  <span class="comment"># 32-bit floating point</span></span><br><span class="line"><span class="built_in">print</span>(</span><br><span class="line">    <span class="comment"># np.matmul==torch.mm  矩阵相乘</span></span><br><span class="line">    <span class="string">&#x27;\nnumpy:&#x27;</span>, np.matmul(data, data),</span><br><span class="line">    <span class="string">&#x27;\ntorch:&#x27;</span>, torch.mm(tensor, tensor)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>



<h3 id="四-自动求导（Autograd）"><a href="#四-自动求导（Autograd）" class="headerlink" title="四  自动求导（Autograd）"></a>四  自动求导（Autograd）</h3><p>torch.autograd是pytorch自动求导的工具，也是所有神经网络的核心。</p>
<p>神经网络(NNs)是作用在输入数据上的一系列嵌套函数的集合，这些函数由权重和误差来定义，被存储在PyTorch中的tensors中。</p>
<ul>
<li>神经网络训练的两个步骤：</li>
</ul>
<p>​    前向传播：在前向传播中，神经网络通过将接收到的数据与每一层对应的权重和误差进行运算来对正确的输出做出最好的预测。</p>
<p>​    反向传播：在反向传播中，神经网络调整其参数使得其与输出误差成比例。反向传播基于梯度下降策略，是链式求导法则的一个应用，以目标的负梯度方向对参数进行调整。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 该部分主要尝试一次训练（前向传播和反向传播）</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line"><span class="comment">#  加载一个预先训练好的模型Resnet18</span></span><br><span class="line">model = torchvision.models.resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line">data = torch.rand(<span class="number">1</span>, <span class="number">3</span>, <span class="number">64</span>, <span class="number">64</span>)</span><br><span class="line">labels = torch.rand(<span class="number">1</span>, <span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对输入数据向输出方向的每一层（代表特征）进行预测，即前向传播</span></span><br><span class="line">prediction = model(data)  <span class="comment"># 前向传播</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 利用模型的预测输出和对应的权重来计算误差，然后进行反响传播误差</span></span><br><span class="line">loss = (prediction - labels).<span class="built_in">sum</span>()</span><br><span class="line">loss.backward()  <span class="comment"># 反向传播</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载优化器，配置各项参数</span></span><br><span class="line">optim = torch.optim.SGD(model.parameters(), lr=<span class="number">1e-2</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最后通过step进行梯度下降，不断调整</span></span><br><span class="line">optim.step() <span class="comment">#梯度下降</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#  至此，一个简单的训练流程就结束了</span></span><br></pre></td></tr></table></figure>

<h3 id="五-优化器（Optimizer"><a href="#五-优化器（Optimizer" class="headerlink" title="五 优化器（Optimizer)"></a>五 优化器（Optimizer)</h3><h5 id="1-是什么？"><a href="#1-是什么？" class="headerlink" title="1 是什么？"></a>1 是什么？</h5><p>一言以蔽之，优化器就是在深度学习反向传播过程中，指引损失函数（目标函数）的各个参数往正确的方向更新合适的大小，使得更新后的各个参数让损失函数（目标函数）值不断逼近全局最小。</p>
<p>待优化参数： <img src="https://www.zhihu.com/equation?tex=%5Comega" alt="[公式]"> ，目标函数： <img src="https://www.zhihu.com/equation?tex=f(x)" alt="[公式]"> ，初始学习率： <img src="https://www.zhihu.com/equation?tex=%5Calpha" alt="[公式]"> ，迭代epoch： <img src="https://www.zhihu.com/equation?tex=t" alt="[公式]"></p>
<p>参数更新步骤如下：</p>
<p>Ⅰ.计算目标函数关于当前参数的梯度：</p>
<blockquote>
<p><img src="https://www.zhihu.com/equation?tex=g_t=%5Cnabla+f(w_t)" alt="[公式]"></p>
</blockquote>
<p>Ⅱ. 根据历史梯度计算一阶动量和二阶动量：</p>
<blockquote>
<p><img src="https://www.zhihu.com/equation?tex=m_t+=+%5Cphi(g_1,+g_2,+%5Ccdots,+g_t);+V_t+=+%5Csum_%7Bi=0%7D%5E%7Bt%7D%7Bx_%7Bi%7D%5E%7B2%7D%7D" alt="[公式]"></p>
</blockquote>
<p>Ⅲ. 计算当前时刻的下降梯度：</p>
<blockquote>
<p><img src="https://www.zhihu.com/equation?tex=%5Ceta_t+=+%5Calpha+%5Ccdot+m_t+/+%5Csqrt%7BV_t%7D" alt="[公式]"></p>
</blockquote>
<p>Ⅳ. 根据下降梯度进行更新参数：</p>
<blockquote>
<p><img src="https://www.zhihu.com/equation?tex=w_%7Bt+1%7D+=+w_t+-+%5Ceta_t" alt="[公式]"></p>
</blockquote>
<p>步骤Ⅲ、Ⅳ对于各个算法都是一致的，主要的差别就体现在步骤Ⅰ、Ⅱ上。</p>
<h5 id="2-有哪些？"><a href="#2-有哪些？" class="headerlink" title="2 有哪些？"></a>2 有哪些？</h5><p>·  随机梯度下降法（Stochastic Gradient Descent，SGD）</p>
<p>·  SGD with Momentum</p>
<p>·  SGD with Nesterov Acceleration</p>
<p>·  AdaGrad（自适应学习率算法）</p>
<p>SGD参数更新公式如下，其中 <img src="https://www.zhihu.com/equation?tex=%5Calpha" alt="[公式]"> 是学习率， <img src="https://www.zhihu.com/equation?tex=g_%7Bt%7D" alt="[公式]"> 是当前参数的梯度</p>
<blockquote>
<p><img src="https://www.zhihu.com/equation?tex=w_%7Bt+1%7D+=w_t+-+%5Calpha+%5Ccdot+g_t+" alt="[公式]"></p>
</blockquote>
<h5 id="3-怎么选？"><a href="#3-怎么选？" class="headerlink" title="3 怎么选？"></a>3 怎么选？</h5><p>总而言之，优化器五花八门，各有优劣。其实主要还是在步长（ <img src="https://www.zhihu.com/equation?tex=%5Calpha" alt="[公式]"> ）和梯度方向（ <img src="https://www.zhihu.com/equation?tex=g_%7Bt%7D" alt="[公式]"> )两个层面进行改进，都是SGD带不同的learning rate scheduler。</p>
<p>作为入门者，还是优先学习SGD+Nesterov Momentum或者Adam吧！</p>
<blockquote>
<p>Tips:更多选择技巧详见收集整理的另一篇：</p>
<hr>
</blockquote>
<h3 id="六-结语"><a href="#六-结语" class="headerlink" title="六 结语"></a>六 结语</h3><p><strong>完成了Pytorch等环境的配置工作，初步学习了神经网络的训练步骤及原理，以及SNN的基本概念。下一步计划继续学习并巩固Numpy、Pytorch等基本语法，学习基本训练流程和方法。</strong></p>
<p><strong>计划在基本入手Pytorch及熟悉了训练基本流程同时，对SNN的原理、差异性、如何实现及优化等进行学习入手</strong></p>
<h3 id="七-文献及资料整理"><a href="#七-文献及资料整理" class="headerlink" title="七 文献及资料整理"></a>七 文献及资料整理</h3><blockquote>
<p>「资料整理」</p>
<p>·Torch目录</p>
<p><a href="https://link.zhihu.com/?target=https://github.com/fengdu78/Data-Science-Notes/tree/master/8.deep-learning/PyTorch_beginner%EF%BC%88%E7%9F%A5%E4%B9%8E%EF%BC%89">https://link.zhihu.com/?target=https%3A//github.com/fengdu78/Data-Science-Notes/tree/master/8.deep-learning/PyTorch_beginner（知乎）</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/fengdu78/Data-Science-Notes/tree/master/8.deep-learning/PyTorch_beginner%EF%BC%88github%EF%BC%89">https://github.com/fengdu78/Data-Science-Notes/tree/master/8.deep-learning/PyTorch_beginner（github）</a></p>
<p>·张量部分</p>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html%EF%BC%88Torch%E7%9A%84%E5%BC%A0%E9%87%8F%E6%93%8D%E4%BD%9C%EF%BC%89">https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html（Torch的张量操作）</a></p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/23720923/answer/32739132%EF%BC%88%E5%BC%A0%E9%87%8F%E7%90%86%E8%A7%A3%EF%BC%89">https://www.zhihu.com/question/23720923/answer/32739132（张量理解）</a></p>
<p>·前向/后向传播与训练（数学推导）</p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/column/p/41138014">https://www.zhihu.com/column/p/41138014</a></p>
<p>·Autograde自动求导</p>
<p>·优化器（Optimizer）</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/261695487">https://zhuanlan.zhihu.com/p/261695487</a></p>
</blockquote>

    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/posts/374b3a70.html" rel="prev" title="「小记」一路前行的故事">
                  <i class="fa fa-chevron-left"></i> 「小记」一路前行的故事
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/posts/cb2ca739.html" rel="next" title="12.27考后测试">
                  12.27考后测试 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>





<script src="/js/comments.js"></script>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Xiao Yao</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/mist/" rel="noopener" target="_blank">NexT.Mist</a> 强力驱动
  </div>





    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <span id="busuanzi_container_site_pv">总访问量<span id="busuanzi_value_site_pv"></span>次</span>
    <span id="busuanzi_container_site_uv">总访客<span id="busuanzi_value_site_uv"></span>人</span>




    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  






  





</body>
</html>
